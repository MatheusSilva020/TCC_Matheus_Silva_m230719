{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIVERSIDADE ESTADUAL DE CAMPINAS\n",
    "# FT - UNICAMP / CURSO SISTEMAS DE INFORMAÇÃO\n",
    "#TCC - CORRETOR ORTOGRÁFICO PARA ANALISE DE TIPOS DE ERROS E SUA RELAÇÃO COM O ANALFABETISMO\n",
    "# AUTOR - MATHEUS EDUARDO DA SILVA \n",
    "# ORIENTADORA -ANA ESTELA ANTUNES DA SILVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup \n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "import os\n",
    "import pandas as pd \n",
    "from nltk.test.portuguese_en_fixt import setup_module\n",
    "import nltk.corpus\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "#lendo o conjunto de corpus C2, e salvando seu conteudo em all_texts.txt:\n",
    "parser = ET.XMLParser(encoding=\"UTF-8\")\n",
    "file = open(\"all_texts.txt\", \"w\", encoding=\"UTF-8\")\n",
    "\n",
    "directory = 'corpus02/ResDialCorpus/C2/'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.xml'):\n",
    "        f = os.path.join(directory, filename)\n",
    "        tree = ET.parse(f)\n",
    "        root = tree.getroot()\n",
    "        text = root.findtext('text')\n",
    "        file.write(text)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de palavras(resumos) é 60678\n",
      "Número de palavras(dicionario PTBR) é 261798\n",
      "Número de palavras(vocabulario Folha SP) é 1012661\n"
     ]
    }
   ],
   "source": [
    "#split_words(): recebe uma lista de strings, e cria um novo vetor que contem somente palavras válidas(sem caracteres nao alfanumericos) \n",
    "def split_words(tokens_list):\n",
    "    list_words = []\n",
    "    for token in tokens_list:\n",
    "        if token.isalpha():\n",
    "            list_words.append(token)\n",
    "    return list_words\n",
    "\n",
    "#registrando palavras dos resumos e historias\n",
    "with open('all_texts.txt', encoding='UTF-8') as f:\n",
    "    contents = f.read()\n",
    "\n",
    "#registrando palavaras do dicionario em ptbr\n",
    "with open('dicionario_USP_ptBr.txt', encoding='UTF-8') as f:\n",
    "    dict_content = f.read()\n",
    "\n",
    "#tokenizando e criando a lista de palavras dos 3 grupos de palavras(vocabulario, dicionário e resumos)\n",
    "contents = nltk.tokenize.word_tokenize(contents)\n",
    "dict_content = nltk.tokenize.word_tokenize(dict_content)\n",
    "folha_sp = nltk.corpus.mac_morpho.words()\n",
    "\n",
    "list_words = split_words(contents)\n",
    "list_words_dict = split_words(dict_content)\n",
    "list_words_voc_common_words_folhasp = split_words(folha_sp)\n",
    "print(f\"Número de palavras(resumos) é {len(list_words)}\")\n",
    "print(f\"Número de palavras(dicionario PTBR) é {len(list_words_dict)}\")\n",
    "print(f\"Número de palavras(vocabulario Folha SP) é {len(list_words_voc_common_words_folhasp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization_words(): normalizando as palavras(tornando todas em minúsculas).\n",
    "def normalization_words(list_words):\n",
    "    normalized_list = []\n",
    "    for word in list_words:\n",
    "        normalized_list.append(word.lower())\n",
    "    return normalized_list\n",
    "\n",
    "normalized_list = normalization_words(list_words)\n",
    "normalized_list_dict = normalization_words(list_words_dict)\n",
    "normalized_list_voc_folhaSP = normalization_words(list_words_voc_common_words_folhasp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valor de frequencia para todas palavras do vocabulário\n",
    "frequency = nltk.FreqDist(normalized_list_voc_folhaSP)\n",
    "\n",
    "#numero de palavras no vocabulario(total)\n",
    "words_total = len(normalized_list_voc_folhaSP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corretor Ortográfico:\n",
    "\n",
    "#known_words(): retorna a lista de palavras e sua classificação de erro caso existam no dicionário.\n",
    "def known_words(words): \n",
    "    lista = set(w for w in words if w[0] in normalized_list_dict)\n",
    "    return lista\n",
    "\n",
    "#candidates_words(): geração de palavras candidatas a possibilidades de correção.\n",
    "def candidates_words(word):\n",
    "    candidates = known_words([word]) | known_words(edits_distance_1(word)) | set([word])\n",
    "    return candidates\n",
    "\n",
    "#probability():Probabilidade da palavra ser a correte dentre as possíveis.\n",
    "def probability(word): \n",
    "    if isinstance(word, tuple) == True:\n",
    "        return (frequency[word[0]] /words_total)\n",
    "    else:\n",
    "        return (frequency[word]/words_total)\n",
    "\n",
    "#correction(): função base do corretor, recebe uma palavra e retorna sua maior probabilidade de correção da palavra.\n",
    "def correction(word):\n",
    "    result = max(candidates_words(word), key=probability)\n",
    "    if isinstance(result, tuple) != True:\n",
    "        return (word, \"\")\n",
    "    else:\n",
    "        return (result)\n",
    "\n",
    "#Possiblidades de correção de palavras:\n",
    "    #Grupos de erros(classificação):\n",
    "    #1- Emprego das consoantes e dos dígrafos + Emprego das formas que representam o som nasal\n",
    "    #2- Emprego de vogais\n",
    "    #3- Acréscimo e omissão de letras\n",
    "    #4- Inversão de letras\n",
    "    #5- Letras com formato semelhante\n",
    "    #6- Erros decorrentes de escritas particulares + Segmentação indevida das palavras\n",
    "    #7- Uso de acentuação\n",
    "\n",
    "#edit_word_insert(): edição de palavras através de adição.\n",
    "def edit_word_insert(word_sliced, letters):\n",
    "    error_group = 3\n",
    "    error_group_content = []\n",
    "    new_possible_words = []\n",
    "    for E, D in word_sliced:\n",
    "        for letter in letters:\n",
    "            new_possible_words.append(E + letter + D)\n",
    "            error_group_content.append(error_group)\n",
    "    words = list(zip(new_possible_words, error_group_content)) \n",
    "    return words\n",
    "\n",
    "#edit_word_delete(): edição de palavras através de remoção.\n",
    "def edit_word_delete(word_sliced, letters):\n",
    "    error_group = 3\n",
    "    error_group_content = []\n",
    "    new_possible_words = []\n",
    "    for E, D in word_sliced:\n",
    "        if len(D) > 0:\n",
    "            new_possible_words.append(E + D[1:])\n",
    "            error_group_content.append(error_group)\n",
    "    words = list(zip(new_possible_words, error_group_content))\n",
    "    return words\n",
    "\n",
    "#edit_word_transpose(): edição de palavras através de transposição.\n",
    "def edit_word_transpose(word_sliced, letters):\n",
    "    error_group = 4\n",
    "    error_group_content = []\n",
    "    new_possible_words = []\n",
    "    for E, D in word_sliced:\n",
    "        if len(D) > 1:\n",
    "            new_possible_words.append(E + D[1] + D[0] + D[2:])\n",
    "            error_group_content.append(error_group)\n",
    "    words = list(zip(new_possible_words, error_group_content))\n",
    "    return words\n",
    "\n",
    "#edit_word_replace(): edição de palavras através de substituição.\n",
    "def edit_word_replace(word_sliced, letters):\n",
    "    error_group = 0 \n",
    "\n",
    "    error_group_content = []\n",
    "    new_possible_words = []\n",
    "    vogals = ['a', 'e', 'i', 'o', 'u']\n",
    "    digrafos = ['ch', 'lh', 'nh', 'rr', 'ss', 'sc', 'sç', 'xc', 'xs', 'am', 'an', 'em', 'en', 'im', 'in', 'om', 'on', 'um', 'un', 'gu', 'qu'] #gu e qu somente nos casos de fonema único(sem som \"/u/\")\n",
    "\n",
    "    letters_equals_p = ['p', 'f', 'q'] \n",
    "    letters_equals_m = ['m', 'n']\n",
    "\n",
    "    accents = ['á', 'â', 'à', 'ã', 'é', 'ê', 'è', 'ẽ', 'í', 'î', 'ì', 'ĩ', 'ó', 'ô', 'õ', 'ò', 'ú', 'û', 'ù', 'ũ', 'ç']\n",
    "    \n",
    "    for E, D in word_sliced:\n",
    "        if len(D) > 0:\n",
    "            for letter in letters:\n",
    "                removed_letter = D[:1]\n",
    "                new_possible_words.append(E + letter + D[1:]) #letra D[0] é substituida\n",
    "                if len(E) > 1 and len(D) > 1:\n",
    "                    possible_digraphs = [(E[-1] + letter), (letter + D[1])]\n",
    "                    next_letter_digraph = D[1:2]\n",
    "                elif len(D) > 1 and len(E) <= 1:\n",
    "                    possible_digraphs = [(E + letter), (letter + D[1])]\n",
    "                    next_letter_digraph = D[1:2]\n",
    "                elif len(E) > 1 and len(D) == 1:\n",
    "                    possible_digraphs = [(E[-1] + letter), (letter)]\n",
    "                    next_letter_digraph = \"\"\n",
    "                else:\n",
    "                    possible_digraphs = [(E + letter), (letter)]\n",
    "                    next_letter_digraph = \"\"\n",
    "\n",
    "                if ((possible_digraphs[0] in digrafos) or (possible_digraphs[1] in digrafos)) and (next_letter_digraph not in vogals and next_letter_digraph != 'h')  and (letter != removed_letter): #se soma letra + letra anterior ou proxima resulta em digrafo\n",
    "                    error_group = 1 #digrafos, consoantes ou sons nasais\n",
    "                elif (((removed_letter in letters_equals_p) and (letter in letters_equals_p)) or ((removed_letter in letters_equals_m) and (letter in letters_equals_m))) and (letter != removed_letter): #erros de formato semelhante\n",
    "                    error_group = 5\n",
    "                elif ((((removed_letter not in vogals) and (removed_letter not in accents)) and ((letter not in vogals) and (letter not in accents)) and (removed_letter not in accents))) and (letter != removed_letter): #consoantes incorretas)\n",
    "                    error_group = 1 #digrafos, consoantes ou sons nasais\n",
    "                elif ((removed_letter in vogals) and (letter in vogals)) and (letter != removed_letter): #vogais incorretas\n",
    "                    error_group = 2 #uso de vogais\n",
    "                elif (((removed_letter in vogals) and (letter in accents)) or (removed_letter == 'c' and letter == 'ç')): #erros de acentuacao\n",
    "                    error_group = 7 #erro de acentuação\n",
    "                else:\n",
    "                    error_group = 6 #erros de escritas particulares\n",
    "                error_group_content.append(error_group)\n",
    "    words = list(zip(new_possible_words, error_group_content))\n",
    "    return words \n",
    "\n",
    "#edits_distance_1(): execução das correções na distância de edição 1 para as palavras no corretor.\n",
    "def edits_distance_1(word):\n",
    "    word_sliced = []\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyzáâàãéêèẽíîìĩóôõòúûùũç'\n",
    "    for i in range(len(word)+1):\n",
    "        word_sliced.append((word[:i], word[i:]))\n",
    "\n",
    "    deletes    = edit_word_delete(word_sliced, letters)\n",
    "    #print(deletes)\n",
    "    inserts    = edit_word_insert(word_sliced, letters)\n",
    "    #print(inserts)\n",
    "    transposes = edit_word_transpose(word_sliced, letters)\n",
    "    #print(transposes)\n",
    "    replaces   = edit_word_replace(word_sliced, letters)\n",
    "    #print(replaces)\n",
    "\n",
    "    return set(deletes + transposes + replaces + inserts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sonho', 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exemplo de uso do corretor ortográfico: recebe uma palavra incorreta, retorna sua correção e a classificação do tipo de erro ocorrido.\n",
    "correction(\"somho\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_test_dataset(): criador de dados de teste.\n",
    "def create_test_dataset(file):\n",
    "    list_words_test = []\n",
    "    correct = ''\n",
    "    wrong = ''\n",
    "    error_group = 0\n",
    "    f = open(file, \"r\", encoding='UTF-8')\n",
    "    for line in f:\n",
    "        correct, wrong, error_group = line.split(\" \", 3)\n",
    "        list_words_test.append((correct, wrong, error_group))\n",
    "    f.close()\n",
    "    return list_words_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust_format(): ajustar formato das saidas do corretor ortografico.\n",
    "def adjust_format(word):\n",
    "    if isinstance(word, tuple) != True:\n",
    "        return (word, \"\" )\n",
    "    else:\n",
    "        return word\n",
    "\n",
    "#evaluate_corrections(): avaliador do corretor ortográfico.\n",
    "    #Grupo WR - correção incorreta e classificação correta\n",
    "    #Grupo RR - correção correta e classificação correta\n",
    "    #Grupo WW - correção incorreta e classificação incorreta\n",
    "    #Grupo RW - correção correta e classificação incorreta\n",
    "def evalutate_corrections(tests, vocabulary):\n",
    "    number_words = len(tests)\n",
    "\n",
    "    right_corrections_right_group = 0\n",
    "    right_corrections_wrong_group = 0\n",
    "    wrong_corrections_right_group = 0\n",
    "    wrong_corrections_wrong_group = 0\n",
    "\n",
    "    list_RR = []\n",
    "    list_RW = []\n",
    "    list_WR = []\n",
    "    list_WW = []\n",
    "    list_unknown = []\n",
    "\n",
    "    unknown = 0\n",
    "    for correct, wrong, error_group in tests:\n",
    "        error_group = error_group[0]\n",
    "        corrected_word = correction(wrong)\n",
    "        corrected_word = adjust_format(corrected_word)\n",
    "        result = [corrected_word[0], corrected_word[1], correct, error_group]\n",
    "        if (correct not in vocabulary):\n",
    "            list_unknown.append(result)\n",
    "            unknown += 1\n",
    "        elif (str(corrected_word[0]) == correct) and (str(corrected_word[1]) == str(error_group)):\n",
    "            list_RR.append(result)\n",
    "            right_corrections_right_group += 1 \n",
    "        elif (str(corrected_word[0]) == correct) and (str(corrected_word[1]) != str(error_group)):\n",
    "            list_RW.append(result)\n",
    "            right_corrections_wrong_group += 1 \n",
    "        elif (str(corrected_word[0]) != correct) and (str(corrected_word[1]) == str(error_group)):\n",
    "            list_WR.append(result)\n",
    "            wrong_corrections_right_group += 1\n",
    "        else:\n",
    "            list_WW.append(result)\n",
    "            wrong_corrections_wrong_group += 1\n",
    "\n",
    "    accuracy_percentage = round(right_corrections_right_group*100/number_words, 2)\n",
    "    accuracy_percentage_error_group = round((right_corrections_right_group + wrong_corrections_right_group)*100/number_words, 2)\n",
    "    unknown_percentage = round(unknown*100/number_words, 2)\n",
    "    print('Grupo WR : ' , list_WR)\n",
    "    print('Grupo RW : ' , list_RW)\n",
    "    print('Grupo WW : ', list_WW)\n",
    "    print('\\n')\n",
    "    print(f\"{accuracy_percentage}% de {number_words} palavras, desconhecida é {unknown_percentage}%,  acurácia de erros de grupo {accuracy_percentage_error_group}%\")\n",
    "    print(\"Palavras Desconhecidas: \" + str(len(list_unknown)))\n",
    "    print(\"Grupo palavras WW: \" + str(len(list_WW)))\n",
    "    print(\"Grupo palavras WR: \" + str(len(list_WR)))\n",
    "    print(\"Grupo palavras RW: \" + str(len(list_RW)))\n",
    "    print(\"Grupo palavras RR: \" + str(len(list_RR)))\n",
    "\n",
    "    return list_RR, list_RW, list_WR, list_WW, list_unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grupo WR :  [['este', 1, 'esse', '1'], ['ele', 2, 'ela', '2'], ['dos', 6, 'das', '6'], ['ele', 2, 'ela', '2'], ['ter', 3, 'terra', '3']]\n",
      "Grupo RW :  [['universo', 1, 'universo', '2'], ['sonho', 5, 'sonho', '1']]\n",
      "Grupo WW :  [['em', 3, 'ele', '1'], ['ptyhon', '', 'python', '4'], ['de', 1, 'ter', '3'], ['em', 3, 'bem', '4'], ['desigm', '', 'design', '5'], ['peça', 6, 'pena', '5'], ['maior', 1, 'valor', '6'], ['ser', 3, 'será', '7'], ['o', 3, 'só', '7'], ['em', 3, 'sem', '1'], ['alexandre', 2, 'alexandria', '3'], ['anos', 1, 'nos', '3'], ['neto', 1, 'luto', '2'], ['ateus', 3, 'mateus', '5'], ['seu', 6, 'eu', '3'], ['perutbar', '', 'perturbar', '4'], ['iria', 6, 'íris', '7'], ['as', 3, 'paz', '1'], ['esteja', 1, 'estrela', '3'], ['ainda', 6, 'vida', '3'], ['melodia', 6, 'melodias', '3'], ['tenente', 1, 'semente', '5'], ['gratipicante', '', 'gratificante', '5'], ['vacinação', 1, 'fascinação', '3'], ['isnpiração', '', 'inspiração', '4']]\n",
      "\n",
      "\n",
      "80.18% de 217 palavras, desconhecida é 5.07%,  acurácia de erros de grupo 82.49%\n",
      "Palavras Desconhecidas: 11\n",
      "Grupo palavras WW: 25\n",
      "Grupo palavras WR: 5\n",
      "Grupo palavras RW: 2\n",
      "Grupo palavras RR: 174\n"
     ]
    }
   ],
   "source": [
    "#criando o corpora para teste do corretor:\n",
    "words_testing_list = create_test_dataset('words_testing.txt')\n",
    "\n",
    "#executando o avaliador do corretor ortográfico:\n",
    "list_RR, list_RW, list_WR, list_WW, list_unknown = evalutate_corrections(words_testing_list, normalized_list_voc_folhaSP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathe\\AppData\\Local\\Temp\\ipykernel_20860\\935058569.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_graphics_WR['ClassificacaoCorrecao'].loc[df_graphics_WR['ClassificacaoCorrecao']==\"\"] = 0\n",
      "C:\\Users\\mathe\\AppData\\Local\\Temp\\ipykernel_20860\\935058569.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_graphics_RW['ClassificacaoCorrecao'].loc[df_graphics_RW['ClassificacaoCorrecao']==\"\"] = 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CorrecaoExecutada</th>\n",
       "      <th>ClassificacaoCorrecao</th>\n",
       "      <th>CorrecaoDesejada</th>\n",
       "      <th>ClassificacaoDesejada</th>\n",
       "      <th>Grupo(Correcao-Classificacao)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>este</td>\n",
       "      <td>1</td>\n",
       "      <td>esse</td>\n",
       "      <td>1</td>\n",
       "      <td>Errada-Correto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ele</td>\n",
       "      <td>2</td>\n",
       "      <td>ela</td>\n",
       "      <td>2</td>\n",
       "      <td>Errada-Correto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dos</td>\n",
       "      <td>6</td>\n",
       "      <td>das</td>\n",
       "      <td>6</td>\n",
       "      <td>Errada-Correto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ele</td>\n",
       "      <td>2</td>\n",
       "      <td>ela</td>\n",
       "      <td>2</td>\n",
       "      <td>Errada-Correto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ter</td>\n",
       "      <td>3</td>\n",
       "      <td>terra</td>\n",
       "      <td>3</td>\n",
       "      <td>Errada-Correto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>universo</td>\n",
       "      <td>1</td>\n",
       "      <td>universo</td>\n",
       "      <td>2</td>\n",
       "      <td>Correta-Errado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sonho</td>\n",
       "      <td>5</td>\n",
       "      <td>sonho</td>\n",
       "      <td>1</td>\n",
       "      <td>Correta-Errado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>em</td>\n",
       "      <td>3</td>\n",
       "      <td>ele</td>\n",
       "      <td>1</td>\n",
       "      <td>Errada-Errado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ptyhon</td>\n",
       "      <td>0</td>\n",
       "      <td>python</td>\n",
       "      <td>4</td>\n",
       "      <td>Errada-Errado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>de</td>\n",
       "      <td>1</td>\n",
       "      <td>ter</td>\n",
       "      <td>3</td>\n",
       "      <td>Errada-Errado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>em</td>\n",
       "      <td>3</td>\n",
       "      <td>bem</td>\n",
       "      <td>4</td>\n",
       "      <td>Errada-Errado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>desigm</td>\n",
       "      <td>0</td>\n",
       "      <td>design</td>\n",
       "      <td>5</td>\n",
       "      <td>Errada-Errado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>peça</td>\n",
       "      <td>6</td>\n",
       "      <td>pena</td>\n",
       "      <td>5</td>\n",
       "      <td>Errada-Errado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>maior</td>\n",
       "      <td>1</td>\n",
       "      <td>valor</td>\n",
       "      <td>6</td>\n",
       "      <td>Errada-Errado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ser</td>\n",
       "      <td>3</td>\n",
       "      <td>será</td>\n",
       "      <td>7</td>\n",
       "      <td>Errada-Errado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>o</td>\n",
       "      <td>3</td>\n",
       "      <td>só</td>\n",
       "      <td>7</td>\n",
       "      <td>Errada-Errado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>em</td>\n",
       "      <td>3</td>\n",
       "      <td>sem</td>\n",
       "      <td>1</td>\n",
       "      <td>Errada-Errado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>alexandre</td>\n",
       "      <td>2</td>\n",
       "      <td>alexandria</td>\n",
       "      <td>3</td>\n",
       "      <td>Errada-Errado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>anos</td>\n",
       "      <td>1</td>\n",
       "      <td>nos</td>\n",
       "      <td>3</td>\n",
       "      <td>Errada-Errado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>neto</td>\n",
       "      <td>1</td>\n",
       "      <td>luto</td>\n",
       "      <td>2</td>\n",
       "      <td>Errada-Errado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ateus</td>\n",
       "      <td>3</td>\n",
       "      <td>mateus</td>\n",
       "      <td>5</td>\n",
       "      <td>Errada-Errado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>seu</td>\n",
       "      <td>6</td>\n",
       "      <td>eu</td>\n",
       "      <td>3</td>\n",
       "      <td>Errada-Errado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>perutbar</td>\n",
       "      <td>0</td>\n",
       "      <td>perturbar</td>\n",
       "      <td>4</td>\n",
       "      <td>Errada-Errado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>iria</td>\n",
       "      <td>6</td>\n",
       "      <td>íris</td>\n",
       "      <td>7</td>\n",
       "      <td>Errada-Errado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>as</td>\n",
       "      <td>3</td>\n",
       "      <td>paz</td>\n",
       "      <td>1</td>\n",
       "      <td>Errada-Errado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>esteja</td>\n",
       "      <td>1</td>\n",
       "      <td>estrela</td>\n",
       "      <td>3</td>\n",
       "      <td>Errada-Errado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ainda</td>\n",
       "      <td>6</td>\n",
       "      <td>vida</td>\n",
       "      <td>3</td>\n",
       "      <td>Errada-Errado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>melodia</td>\n",
       "      <td>6</td>\n",
       "      <td>melodias</td>\n",
       "      <td>3</td>\n",
       "      <td>Errada-Errado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tenente</td>\n",
       "      <td>1</td>\n",
       "      <td>semente</td>\n",
       "      <td>5</td>\n",
       "      <td>Errada-Errado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gratipicante</td>\n",
       "      <td>0</td>\n",
       "      <td>gratificante</td>\n",
       "      <td>5</td>\n",
       "      <td>Errada-Errado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>vacinação</td>\n",
       "      <td>1</td>\n",
       "      <td>fascinação</td>\n",
       "      <td>3</td>\n",
       "      <td>Errada-Errado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>isnpiração</td>\n",
       "      <td>0</td>\n",
       "      <td>inspiração</td>\n",
       "      <td>4</td>\n",
       "      <td>Errada-Errado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CorrecaoExecutada ClassificacaoCorrecao CorrecaoDesejada  \\\n",
       "0               este                     1             esse   \n",
       "1                ele                     2              ela   \n",
       "2                dos                     6              das   \n",
       "3                ele                     2              ela   \n",
       "4                ter                     3            terra   \n",
       "0           universo                     1         universo   \n",
       "1              sonho                     5            sonho   \n",
       "0                 em                     3              ele   \n",
       "1             ptyhon                     0           python   \n",
       "2                 de                     1              ter   \n",
       "3                 em                     3              bem   \n",
       "4             desigm                     0           design   \n",
       "5               peça                     6             pena   \n",
       "6              maior                     1            valor   \n",
       "7                ser                     3             será   \n",
       "8                  o                     3               só   \n",
       "9                 em                     3              sem   \n",
       "10         alexandre                     2       alexandria   \n",
       "11              anos                     1              nos   \n",
       "12              neto                     1             luto   \n",
       "13             ateus                     3           mateus   \n",
       "14               seu                     6               eu   \n",
       "15          perutbar                     0        perturbar   \n",
       "16              iria                     6             íris   \n",
       "17                as                     3              paz   \n",
       "18            esteja                     1          estrela   \n",
       "19             ainda                     6             vida   \n",
       "20           melodia                     6         melodias   \n",
       "21           tenente                     1          semente   \n",
       "22      gratipicante                     0     gratificante   \n",
       "23         vacinação                     1       fascinação   \n",
       "24        isnpiração                     0       inspiração   \n",
       "\n",
       "   ClassificacaoDesejada Grupo(Correcao-Classificacao)  \n",
       "0                      1                Errada-Correto  \n",
       "1                      2                Errada-Correto  \n",
       "2                      6                Errada-Correto  \n",
       "3                      2                Errada-Correto  \n",
       "4                      3                Errada-Correto  \n",
       "0                      2                Correta-Errado  \n",
       "1                      1                Correta-Errado  \n",
       "0                      1                 Errada-Errado  \n",
       "1                      4                 Errada-Errado  \n",
       "2                      3                 Errada-Errado  \n",
       "3                      4                 Errada-Errado  \n",
       "4                      5                 Errada-Errado  \n",
       "5                      5                 Errada-Errado  \n",
       "6                      6                 Errada-Errado  \n",
       "7                      7                 Errada-Errado  \n",
       "8                      7                 Errada-Errado  \n",
       "9                      1                 Errada-Errado  \n",
       "10                     3                 Errada-Errado  \n",
       "11                     3                 Errada-Errado  \n",
       "12                     2                 Errada-Errado  \n",
       "13                     5                 Errada-Errado  \n",
       "14                     3                 Errada-Errado  \n",
       "15                     4                 Errada-Errado  \n",
       "16                     7                 Errada-Errado  \n",
       "17                     1                 Errada-Errado  \n",
       "18                     3                 Errada-Errado  \n",
       "19                     3                 Errada-Errado  \n",
       "20                     3                 Errada-Errado  \n",
       "21                     5                 Errada-Errado  \n",
       "22                     5                 Errada-Errado  \n",
       "23                     3                 Errada-Errado  \n",
       "24                     4                 Errada-Errado  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#criação de dataframe para análises:\n",
    "columns = ['CorrecaoExecutada', 'ClassificacaoCorrecao', 'CorrecaoDesejada', 'ClassificacaoDesejada']\n",
    "df_graphics_WR = pd.DataFrame(list_WR, columns=columns)\n",
    "df_graphics_RW = pd.DataFrame(list_RW, columns=columns)\n",
    "df_graphics_WW = pd.DataFrame(list_WW, columns=columns)\n",
    "\n",
    "df_graphics_WR['ClassificacaoCorrecao'].loc[df_graphics_WR['ClassificacaoCorrecao']==\"\"] = 0\n",
    "df_graphics_RW['ClassificacaoCorrecao'].loc[df_graphics_RW['ClassificacaoCorrecao']==\"\"] = 0\n",
    "df_graphics_WW['ClassificacaoCorrecao'].loc[df_graphics_WW['ClassificacaoCorrecao']==\"\"] = 0\n",
    "\n",
    "df_graphics_WW['Grupo(Correcao-Classificacao)'] = 'Errada-Errado'\n",
    "df_graphics_WR['Grupo(Correcao-Classificacao)'] = 'Errada-Correto'\n",
    "df_graphics_RW['Grupo(Correcao-Classificacao)'] = 'Correta-Errado'\n",
    "\n",
    "df_errors = pd.concat([df_graphics_WR, df_graphics_RW, df_graphics_WW])\n",
    "df_errors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
