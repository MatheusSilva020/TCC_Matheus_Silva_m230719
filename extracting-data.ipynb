{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIVERSIDADE ESTADUAL DE CAMPINAS\n",
    "# FT - UNICAMP / CURSO SISTEMAS DE INFORMAÇÃO\n",
    "#TCC - CORRETOR ORTOGRÁFICO PARA ANALISE DE TIPOS DE ERROS E SUA RELAÇÃO COM O ANALFABETISMO\n",
    "# AUTOR - MATHEUS EDUARDO DA SILVA RA: 230719\n",
    "# ORIENTADORA -ANA ESTELA ANTUNES DA SILVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup \n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "import os\n",
    "import pandas as pd \n",
    "from nltk.test.portuguese_en_fixt import setup_module\n",
    "import nltk.corpus\n",
    "\n",
    "#lendo o conjunto de corpus C2, e salvando seu conteudo em all_texts.txt:\n",
    "parser = ET.XMLParser(encoding=\"UTF-8\")\n",
    "file = open(\"all_texts.txt\", \"w\", encoding=\"UTF-8\")\n",
    "\n",
    "directory = 'corpus02/ResDialCorpus/C2/'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.xml'):\n",
    "        f = os.path.join(directory, filename)\n",
    "        tree = ET.parse(f)\n",
    "        root = tree.getroot()\n",
    "        text = root.findtext('text')\n",
    "        file.write(text)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de palavras(resumos) é 60678\n",
      "Número de palavras(dicionario PTBR) é 261798\n",
      "Número de palavras(dicionario Folha SP) é 1012661\n"
     ]
    }
   ],
   "source": [
    "#split_words(): recebe uma lista de strings, e cria um novo vetor que contem somente palavras válidas(sem caracteres nao alfanumericos) \n",
    "def split_words(tokens_list):\n",
    "    list_words = []\n",
    "    for token in tokens_list:\n",
    "        if token.isalpha():\n",
    "            list_words.append(token)\n",
    "    return list_words\n",
    "\n",
    "#registrando palavras dos resumos e historias\n",
    "with open('all_texts.txt', encoding='UTF-8') as f:\n",
    "    contents = f.read()\n",
    "\n",
    "#registrando palavaras do dicionario em ptbr\n",
    "with open('dicionario_USP_ptBr.txt', encoding='UTF-8') as f:\n",
    "    dict_content = f.read()\n",
    "\n",
    "#tokenizando e criando a lista de palavras dos 2 grupos de palavras(dicionário e resumos)\n",
    "contents = nltk.tokenize.word_tokenize(contents)\n",
    "dict_content = nltk.tokenize.word_tokenize(dict_content)\n",
    "folha_sp = nltk.corpus.mac_morpho.words()\n",
    "\n",
    "list_words = split_words(contents)\n",
    "list_words_dict = split_words(dict_content)\n",
    "list_words_dict_common_words_folhasp = split_words(folha_sp)\n",
    "print(f\"Número de palavras(resumos) é {len(list_words)}\")\n",
    "print(f\"Número de palavras(dicionario PTBR) é {len(list_words_dict)}\")\n",
    "print(f\"Número de palavras(dicionario Folha SP) é {len(list_words_dict_common_words_folhasp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizando as palavras(tornando todas em minúsculas):\n",
    "def normalization_words(list_words):\n",
    "    normalized_list = []\n",
    "    for word in list_words:\n",
    "        normalized_list.append(word.lower())\n",
    "    return normalized_list\n",
    "\n",
    "normalized_list = normalization_words(list_words)\n",
    "normalized_list_dict = normalization_words(list_words_dict)\n",
    "normalized_list_dict_folhaSP = normalization_words(list_words_dict_common_words_folhasp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mathe\\OneDrive\\Documentos\\Matheus\\UNICAMP\\TCC\\vsCode_TCC\\extracting-data.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mathe/OneDrive/Documentos/Matheus/UNICAMP/TCC/vsCode_TCC/extracting-data.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m database\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mathe/OneDrive/Documentos/Matheus/UNICAMP/TCC/vsCode_TCC/extracting-data.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m#lista que relaciona as palavras do resumo com o dicionário(REMOVER PALAVRAS REPETIDAS)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mathe/OneDrive/Documentos/Matheus/UNICAMP/TCC/vsCode_TCC/extracting-data.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m database_words_analysis \u001b[39m=\u001b[39m create_database_words_analysis(normalized_list, normalized_list_dict)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mathe/OneDrive/Documentos/Matheus/UNICAMP/TCC/vsCode_TCC/extracting-data.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(database_words_analysis)\n",
      "\u001b[1;32mc:\\Users\\mathe\\OneDrive\\Documentos\\Matheus\\UNICAMP\\TCC\\vsCode_TCC\\extracting-data.ipynb Cell 5\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mathe/OneDrive/Documentos/Matheus/UNICAMP/TCC/vsCode_TCC/extracting-data.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mif\u001b[39;00m word \u001b[39min\u001b[39;00m list_words_dict_normalized:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mathe/OneDrive/Documentos/Matheus/UNICAMP/TCC/vsCode_TCC/extracting-data.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     line \u001b[39m=\u001b[39m [word, word]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mathe/OneDrive/Documentos/Matheus/UNICAMP/TCC/vsCode_TCC/extracting-data.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     database\u001b[39m.\u001b[39mappend(line)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mathe/OneDrive/Documentos/Matheus/UNICAMP/TCC/vsCode_TCC/extracting-data.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mathe/OneDrive/Documentos/Matheus/UNICAMP/TCC/vsCode_TCC/extracting-data.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     line \u001b[39m=\u001b[39m [word, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def create_database_words_analysis(list_words_normalized, list_words_dict_normalized):\n",
    "    database = []\n",
    "    for word in list_words_normalized:\n",
    "        if word in list_words_dict_normalized:\n",
    "            line = [word, word]\n",
    "            database.append(line)\n",
    "        else:\n",
    "            line = [word, \"\"]\n",
    "            database.append(line)\n",
    "\n",
    "    return database\n",
    "\n",
    "#lista que relaciona as palavras do resumo com o dicionário(REMOVER PALAVRAS REPETIDAS)\n",
    "database_words_analysis = create_database_words_analysis(normalized_list, normalized_list_dict)\n",
    "print(database_words_analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Palavra</th>\n",
       "      <th>Dicionario(palavra referente)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cliente</td>\n",
       "      <td>cliente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>da</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lanchonete</td>\n",
       "      <td>lanchonete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>quer</td>\n",
       "      <td>quer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60673</th>\n",
       "      <td>irrita</td>\n",
       "      <td>irrita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60674</th>\n",
       "      <td>com</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60675</th>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60676</th>\n",
       "      <td>pedido</td>\n",
       "      <td>pedido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60677</th>\n",
       "      <td>ultrapassado</td>\n",
       "      <td>ultrapassado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60678 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Palavra Dicionario(palavra referente)\n",
       "0                 o                             o\n",
       "1           cliente                       cliente\n",
       "2                da                            da\n",
       "3        lanchonete                    lanchonete\n",
       "4              quer                          quer\n",
       "...             ...                           ...\n",
       "60673        irrita                        irrita\n",
       "60674           com                           com\n",
       "60675             o                             o\n",
       "60676        pedido                        pedido\n",
       "60677  ultrapassado                  ultrapassado\n",
       "\n",
       "[60678 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cirando um dataframe com relação de palavras conhecidas e desconhecidas\n",
    "df_dictionary = pd.DataFrame(database_words_analysis, columns=['Palavra', 'Dicionario(palavra referente)'] )\n",
    "df_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Palavra                          3942\n",
       "Dicionario(palavra referente)    3942\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#numero de palavras desconhecidas ao dicionario\n",
    "database_words_analysis[1].count(\"\")\n",
    "count_unknown_words = df_dictionary.loc[df_dictionary['Dicionario(palavra referente)'] ==''].count()\n",
    "count_unknown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FAZER O TESTE DO CORRETOR ORTOGRÁFICO\n",
    "#FAZER UMA RELAÇAO COM PALAVRAS DESCONHECIDAS (\"META PARA CORRIGIR\")\n",
    "#CRIAR TIPOS DE CLASSIFICACAO(ERROS DE ASPECTOS VISUAIS E GRAFICOS + ERROS DE RELAÇÕES ENTRE LETRAS E SONS( VARIAS SUBCLASSES))\n",
    "\n",
    "# -----> AQUI PODEM TER n CLASSES CASO QUEIRA SER ESPECIFICO\n",
    "#COMPARAR COM O TRABALHO E VER SE OS NÚMEROS ESTÃO BATENDO\n",
    "#COMPARAR E FAZER ANALISE GRÁFICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('de', 88320),\n",
       " ('a', 68966),\n",
       " ('o', 61303),\n",
       " ('em', 34383),\n",
       " ('e', 22551),\n",
       " ('que', 20666),\n",
       " ('os', 16989),\n",
       " ('para', 11122),\n",
       " ('as', 10720),\n",
       " ('por', 10311)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency = nltk.FreqDist(normalized_list_dict_folhaSP)\n",
    "words_total = len(normalized_list_dict_folhaSP)\n",
    "frequency.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# TO DO \n",
    "#checar funcionalidade dos error groups\n",
    "#checar como retornar palavra já correta\n",
    "#checar palavra correta onde é igual a original (NORVIG)\n",
    "#criar base textual\n",
    "#criar avaliador\n",
    "\n",
    "def known_words(words): \n",
    "    lista = set(w for w in words if w[0] in normalized_list_dict)\n",
    "    return lista\n",
    "\n",
    "\n",
    "#Geração de palavras candidatas a possibilidades de correção\n",
    "def candidates_words(word):\n",
    "    candidates = known_words([word]) | known_words(edits_distance_1(word)) | set([word])\n",
    "    return candidates\n",
    "    #return (known_words([word]) or (known_words(edits_distance_1([word]))) or [word])\n",
    "\n",
    "#Probabilidade da palavra ser a correte dentre as possíveis:\n",
    "    #usar contexto do texto da Folha SP\n",
    "def probability(word): \n",
    "    if isinstance(word, tuple) == True:\n",
    "        return (frequency[word[0]] /words_total)\n",
    "    else:\n",
    "        return (frequency[word]/words_total)\n",
    "\n",
    "\n",
    "#CORRIGIR ISSO AQUI \n",
    "#Maior probabilidade de correção da palavra\n",
    "def correction(word):\n",
    "    result = max(candidates_words(word), key=probability) #, default=word)\n",
    "    if isinstance(result, tuple) != True:\n",
    "        return (word, \"\")\n",
    "    else:\n",
    "        return (result)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#EDIT WORDS POSSIBILITIES\n",
    "    #GRUPOS DE ERROS:\n",
    "    #1- Emprego das consoantes e dos dígrafos + Emprego das formas que representam o som nasal\n",
    "    #2- Emprego de vogais\n",
    "    #3- Acréscimo e omissão de letras\n",
    "    #4- Inversão de letras\n",
    "    #5- Letras com formato semelhante\n",
    "    #6- Erros decorrentes de escritas particulares + Segmentação indevida das palavras\n",
    "    #7- Uso de acentuação\n",
    "\n",
    "def edit_word_insert(word_sliced, letters):\n",
    "    error_group = 3\n",
    "    error_group_content = []\n",
    "    new_possible_words = []\n",
    "    for E, D in word_sliced:\n",
    "        for letter in letters:\n",
    "            new_possible_words.append(E + letter + D)\n",
    "            error_group_content.append(error_group)\n",
    "    words = list(zip(new_possible_words, error_group_content))\n",
    "    \n",
    "    return words\n",
    "\n",
    "def edit_word_delete(word_sliced, letters):\n",
    "    error_group = 3\n",
    "    error_group_content = []\n",
    "    new_possible_words = []\n",
    "    for E, D in word_sliced:\n",
    "        if len(D) > 0:\n",
    "            new_possible_words.append(E + D[1:])\n",
    "            error_group_content.append(error_group)\n",
    "    words = list(zip(new_possible_words, error_group_content))\n",
    "\n",
    "    return words\n",
    "\n",
    "def edit_word_transpose(word_sliced, letters):\n",
    "    error_group = 4\n",
    "    error_group_content = []\n",
    "    new_possible_words = []\n",
    "    for E, D in word_sliced:\n",
    "        if len(D) > 1:\n",
    "            new_possible_words.append(E + D[1] + D[0] + D[2:])\n",
    "            error_group_content.append(error_group)\n",
    "    words = list(zip(new_possible_words, error_group_content))\n",
    "\n",
    "    return words\n",
    "\n",
    "#corrgir - existe insercao no for de substituicao(ultima letra extra)\n",
    "def edit_word_replace(word_sliced, letters):\n",
    "    error_group = 0 # POR PADRAO SER ESCRITA ESPECIFICA\n",
    "\n",
    "    error_group_content = []\n",
    "    new_possible_words = []\n",
    "    vogals = ['a', 'e', 'i', 'o', 'u']\n",
    "    digrafos = ['ch', 'lh', 'nh', 'rr', 'ss', 'sc', 'sç', 'xc', 'xs', 'am', 'an', 'em', 'en', 'im', 'in', 'om', 'on', 'um', 'un', 'gu', 'qu'] #gu e qu somente nos casos de fonema único(sem som \"/u/\")\n",
    "    \n",
    "    letters_equals_p = ['p', 'f', 'q'] #melhorar as opções aqui\n",
    "    letters_equals_m = ['m', 'n']\n",
    "\n",
    "    accents = ['á', 'â','à','ã','é', 'ê', 'è', 'ẽ', 'í','î', 'ì','ĩ' 'ó', 'ô', 'õ', 'ò', 'ú', 'û', 'ù', 'ũ', 'ç']\n",
    "    for E, D in word_sliced:\n",
    "        if len(D) > 0:\n",
    "            for letter in letters:\n",
    "                removed_letter = D[:1]\n",
    "                new_possible_words.append(E + letter + D[1:]) #letra D[0] é substituida\n",
    "                if len(E) > 1 and len(D) > 1:\n",
    "                    possible_digraphs = [(E[-1] + letter), (letter + D[1])]\n",
    "                elif len(D) > 1:\n",
    "                    possible_digraphs = [(E + letter), (letter + D[1])]\n",
    "                elif len(E) > 1:\n",
    "                    possible_digraphs = [(E[-1] + letter), (letter + D)]\n",
    "                else:\n",
    "                    possible_digraphs = [(E + letter), (letter + D)]\n",
    "\n",
    "                if ((possible_digraphs[0] in digrafos) or (possible_digraphs[1] in digrafos)) and (letter != removed_letter): #se soma letra + letra anterior ou proxima resulta em digrafo\n",
    "                    error_group = 1 #digrafos, consoantes ou sons nasais\n",
    "                elif ((removed_letter in letters_equals_p and letters in letters_equals_p) or (removed_letter in letters_equals_m and letters in letters_equals_m)) and (letter != removed_letter): #erros de formato semelhante\n",
    "                    error_group = 5\n",
    "                elif (((removed_letter not in vogals) and (letter not in vogals) and (letter not in accents) and (removed_letter not in accents))) and (letter != removed_letter): #consoantes incorretas\n",
    "                    error_group = 1 #digrafos, consoantes ou sons nasais\n",
    "                elif ((removed_letter in vogals) and (letter in vogals)) and (letter != removed_letter): #vogais incorretas\n",
    "                    error_group = 2 #uso de vogais\n",
    "                elif ((removed_letter in vogals) and (letter in accents)) or (removed_letter == 'c' and letter == 'ç') and (letter != removed_letter): #erros de acentuacao\n",
    "                    error_group = 7 #erro de acentuação\n",
    "                else:\n",
    "                    error_group = 6 #erros de escritas particulares\n",
    "                error_group_content.append(error_group)\n",
    "    words = list(zip(new_possible_words, error_group_content))\n",
    "\n",
    "    return words \n",
    "\n",
    "\n",
    "#distâncias de edição para as palavras no corretor\n",
    "def edits_distance_1(word):\n",
    "    word_sliced = []\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyzáâàãéêèẽíîìĩóôõòúûùũç'\n",
    "    for i in range(len(word)+1):\n",
    "        word_sliced.append((word[:i], word[i:]))\n",
    "\n",
    "    deletes    = edit_word_delete(word_sliced, letters)\n",
    "    #print(deletes)\n",
    "    inserts    = edit_word_insert(word_sliced, letters)\n",
    "    #print(inserts)\n",
    "    transposes = edit_word_transpose(word_sliced, letters)\n",
    "    #print(transposes)\n",
    "    replaces   = edit_word_replace(word_sliced, letters)\n",
    "    #print(replaces)\n",
    "\n",
    "    return set(deletes + transposes + replaces + inserts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00017972450800415933"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability(\"familia\") #CORRIGIR\n",
    "#print(probability('água') > probability('agua'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('esse', 4)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction(\"eses\") # Corrigir grupos de erro 1, 2, 5, 6 e 7 palavra água"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.nltk.org/nltk_data/'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'https://www.nltk.org/howto/portuguese_en.html'\n",
    "\n",
    "'https://docs.huihoo.com/nltk/0.9.5/guides/portuguese_en.html'\n",
    "\n",
    "'https://direct.mit.edu/coli/article/41/1/175/1493/Spelling-Error-Patterns-in-Brazilian-Portuguese'\n",
    "\n",
    "' http://rbep.inep.gov.br/ojs3/index.php/rbep/article/view/1506/1245'\n",
    "\n",
    "'https://www.nltk.org/howto/portuguese_en.html'\n",
    "'https://www.nltk.org/nltk_data/' # MAC Morpho\n",
    "\n",
    "#wordnet -> criar/usar uma lista de palavras(dicionário) - check\n",
    "#.txt -> criar uma lista de palavras - \n",
    "#criar um .csv com a relação palavra do txt x dicionario(atraves do corretor?)\n",
    "#criar um .txt para base de teste (200 250 palavras erradas + correta + classificação de correção)\n",
    "#dividir o .txt anterior para base de treino e teste\n",
    "#criar o classificador ortográfico de erros sobre analfabetismo(estudar e pensar nos subgrupos) - check 1/2\n",
    "#fazer analytics com os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criador de dados de teste: (a alterar e adaptar)\n",
    "def create_test_dataset(file):\n",
    "    list_words_test = []\n",
    "    correct = ''\n",
    "    wrong = ''\n",
    "    error_group = 0\n",
    "    f = open(file, \"r\", encoding='UTF-8')\n",
    "    for line in f:\n",
    "        correct, wrong, error_group = line.split(\" \", 3)\n",
    "        list_words_test.append((correct, wrong, error_group))\n",
    "    f.close()\n",
    "    return list_words_test\n",
    "\n",
    "#lista_teste = create_test_dataset(\"palavras.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ajustar formato das saidas do corretor:\n",
    "def adjust_format(word):\n",
    "    if isinstance(word, tuple) != True:\n",
    "        return (word, \"\" )\n",
    "    else:\n",
    "        return word\n",
    "\n",
    "#avaliador do corretor ortográfico: ( corrigir para mostrar as porcentagens de tipo de erro)\n",
    "def evalutate_corrections(tests, vocabulary):\n",
    "    number_words = len(tests)\n",
    "\n",
    "    right_corrections_right_group = 0\n",
    "    right_corrections_wrong_group = 0\n",
    "    wrong_corrections_right_group = 0\n",
    "    wrong_corrections_wrong_group = 0\n",
    "    unknown = 0\n",
    "    for correct, wrong, error_group in tests:\n",
    "        error_group = error_group[0]\n",
    "        #corrected_word: word, error_group(made)\n",
    "        corrected_word = correction(wrong)\n",
    "        corrected_word = adjust_format(corrected_word)\n",
    "        unknown += (correct not in vocabulary)\n",
    "\n",
    "        if (str(corrected_word[0]) == correct) and (str(corrected_word[1]) == str(error_group)):\n",
    "            right_corrections_right_group += 1 \n",
    "        elif (str(corrected_word[0]) == correct) and (str(corrected_word[1]) != str(error_group)):\n",
    "            right_corrections_wrong_group += 1 \n",
    "            print(\"Word(wrong/correction/right):\" + wrong + \" - \"  + str(corrected_word[0]) + \" - \" + correct + \" *  Groups(wrong/right): \" + str(corrected_word[1]) + \"-\" + error_group)\n",
    "        elif (str(corrected_word[0]) != correct) and (str(corrected_word[1]) == str(error_group)):\n",
    "            wrong_corrections_right_group += 1\n",
    "            print(\"Word(wrong/correction/right):\" + wrong +  \" - \" + str(corrected_word[0]) + \" - \" + correct + \" *  Groups(wrong/right): \" + str(corrected_word[1]) + \"-\" + error_group)\n",
    "        else:\n",
    "            wrong_corrections_wrong_group += 1\n",
    "            print(\"Word(wrong/correction/right):\" + wrong  + \" - \" + str(corrected_word[0]) + \" - \" + correct + \" *  Groups(wrong/right): \" + str(corrected_word[1]) + \"-\" + error_group)\n",
    "\n",
    "    accuracy_percentage = round(right_corrections_right_group*100/number_words, 2)\n",
    "    accuracy_percentage_error_group = round((right_corrections_right_group + wrong_corrections_right_group)*100/number_words, 2)\n",
    "    unknown_percentage = round(unknown*100/number_words, 2)\n",
    "    print(f\"{accuracy_percentage}% de {number_words} palavras, desconhecida é {unknown_percentage}%,  acurácia de erros de grupo {accuracy_percentage_error_group}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word(wrong/correction/right):esje - este - esse *  Groups(wrong/right): 1-1\n",
      "Word(wrong/correction/right):eme - em - ele *  Groups(wrong/right): 3-1\n",
      "Word(wrong/correction/right):quaôdo - quando - quando *  Groups(wrong/right): 1-6\n",
      "Word(wrong/correction/right):sjava - soava - java *  Groups(wrong/right): 6-3\n",
      "Word(wrong/correction/right):eòtá - está - está *  Groups(wrong/right): 6-3\n",
      "Word(wrong/correction/right):tim - tem - tem *  Groups(wrong/right): 1-2\n",
      "Word(wrong/correction/right):ptyhon - ptyhon - python *  Groups(wrong/right): -4\n",
      "Word(wrong/correction/right):assem - assim - assim *  Groups(wrong/right): 1-2\n",
      "Word(wrong/correction/right):te - de - ter *  Groups(wrong/right): 1-3\n",
      "Word(wrong/correction/right):ebm - em - bem *  Groups(wrong/right): 3-4\n",
      "Word(wrong/correction/right):desigm - desigm - design *  Groups(wrong/right): -5\n",
      "Word(wrong/correction/right):apemas - apenas - apenas *  Groups(wrong/right): 1-5\n",
      "Word(wrong/correction/right):emqresa - empresa - empresa *  Groups(wrong/right): 1-5\n",
      "Word(wrong/correction/right):vaior - maior - valor *  Groups(wrong/right): 1-6\n",
      "Word(wrong/correction/right):sera - ser - será *  Groups(wrong/right): 3-7\n",
      "Word(wrong/correction/right):frecisamos - precisamos - precisamos *  Groups(wrong/right): 1-5\n",
      "Word(wrong/correction/right):van - vai - vai *  Groups(wrong/right): 1-6\n",
      "Word(wrong/correction/right):çeus - seus - seus *  Groups(wrong/right): 6-1\n",
      "Word(wrong/correction/right):temqo - tempo - tempo *  Groups(wrong/right): 1-5\n",
      "Word(wrong/correction/right):pual - qual - qual *  Groups(wrong/right): 1-5\n",
      "Word(wrong/correction/right):eli - ele - ela *  Groups(wrong/right): 2-2\n",
      "Word(wrong/correction/right):so - o - só *  Groups(wrong/right): 3-7\n",
      "Word(wrong/correction/right):siàe - siàe - site *  Groups(wrong/right): -6\n",
      "Word(wrong/correction/right):cem - em - sem *  Groups(wrong/right): 3-1\n",
      "Word(wrong/correction/right):peln - pelo - pelo *  Groups(wrong/right): 1-6\n",
      "Word(wrong/correction/right):alexandra - alexandre - alexandria *  Groups(wrong/right): 2-3\n",
      "Word(wrong/correction/right):dms - dos - das *  Groups(wrong/right): 6-6\n",
      "Word(wrong/correction/right):ános - anos - nos *  Groups(wrong/right): 1-3\n",
      "Word(wrong/correction/right):usuárin - usuário - usuário *  Groups(wrong/right): 1-6\n",
      "Word(wrong/correction/right):leto - neto - luto *  Groups(wrong/right): 1-2\n",
      "Word(wrong/correction/right):búm - bem - bem *  Groups(wrong/right): 1-6\n",
      "Word(wrong/correction/right):nétodo - método - método *  Groups(wrong/right): 1-5\n",
      "Word(wrong/correction/right):nateus - ateus - mateus *  Groups(wrong/right): 3-5\n",
      "Word(wrong/correction/right):ìeu - seu - eu *  Groups(wrong/right): 6-3\n",
      "Word(wrong/correction/right):fual - qual - qual *  Groups(wrong/right): 1-5\n",
      "Word(wrong/correction/right):elu - ele - ela *  Groups(wrong/right): 2-2\n",
      "Word(wrong/correction/right):enpoderamento - enpoderamento - empoderamento *  Groups(wrong/right): -1\n",
      "Word(wrong/correction/right):relogio - relógio - relógio *  Groups(wrong/right): 6-7\n",
      "Word(wrong/correction/right):camela - canela - canela *  Groups(wrong/right): 1-5\n",
      "Word(wrong/correction/right):emfoderamento - emfoderamento - empoderamento *  Groups(wrong/right): -5\n",
      "Word(wrong/correction/right):entertido - entertido - entretido *  Groups(wrong/right): -4\n",
      "Word(wrong/correction/right):toamra - toamra - tomara *  Groups(wrong/right): -4\n",
      "Word(wrong/correction/right):perutbar - perutbar - perturbar *  Groups(wrong/right): -4\n",
      "Word(wrong/correction/right):iris - iria - íris *  Groups(wrong/right): 6-7\n",
      "Word(wrong/correction/right):pas - as - paz *  Groups(wrong/right): 3-1\n",
      "Word(wrong/correction/right):dansa - dança - dança *  Groups(wrong/right): 6-1\n",
      "Word(wrong/correction/right):oniverso - universo - universo *  Groups(wrong/right): 1-2\n",
      "Word(wrong/correction/right):memoria - memória - memória *  Groups(wrong/right): 6-7\n",
      "Word(wrong/correction/right):tera - ter - terra *  Groups(wrong/right): 3-3\n",
      "Word(wrong/correction/right):estela - esteja - estrela *  Groups(wrong/right): 1-3\n",
      "Word(wrong/correction/right):nontanha - montanha - montanha *  Groups(wrong/right): 1-5\n",
      "Word(wrong/correction/right):puerer - querer - querer *  Groups(wrong/right): 1-5\n",
      "Word(wrong/correction/right):nagia - magia - magia *  Groups(wrong/right): 1-5\n",
      "Word(wrong/correction/right):anizade - amizade - amizade *  Groups(wrong/right): 1-5\n",
      "Word(wrong/correction/right):vinda - ainda - vida *  Groups(wrong/right): 6-3\n",
      "Word(wrong/correction/right):conhecinento - conhecimento - conhecimento *  Groups(wrong/right): 1-5\n",
      "Word(wrong/correction/right):abobora - abóbora - abóbora *  Groups(wrong/right): 6-7\n",
      "Word(wrong/correction/right):potografia - fotografia - fotografia *  Groups(wrong/right): 1-5\n",
      "Word(wrong/correction/right):ananhecer - amanhecer - amanhecer *  Groups(wrong/right): 1-5\n",
      "Word(wrong/correction/right):pelicidade - felicidade - felicidade *  Groups(wrong/right): 1-5\n",
      "Word(wrong/correction/right):melodia - melodia - melodias *  Groups(wrong/right): 6-3\n",
      "Word(wrong/correction/right):senente - tenente - semente *  Groups(wrong/right): 1-5\n",
      "Word(wrong/correction/right):renovaçãn - renovação - renovação *  Groups(wrong/right): 1-6\n",
      "Word(wrong/correction/right):gratipicante - gratipicante - gratificante *  Groups(wrong/right): -5\n",
      "Word(wrong/correction/right):facinação - vacinação - fascinação *  Groups(wrong/right): 1-3\n",
      "Word(wrong/correction/right):resiliencia - resiliencia - resiliência *  Groups(wrong/right): -7\n",
      "Word(wrong/correction/right):encantanento - encantamento - encantamento *  Groups(wrong/right): 1-5\n",
      "Word(wrong/correction/right):deslumrbe - deslumrbe - deslumbre *  Groups(wrong/right): -4\n",
      "Word(wrong/correction/right):isnpiração - isnpiração - inspiração *  Groups(wrong/right): -4\n",
      "68.2% de 217 palavras, desconhecida é 5.07%,  acurácia de erros de grupo 70.51%\n"
     ]
    }
   ],
   "source": [
    "words_testing_list = create_test_dataset('words_testing.txt')\n",
    "evalutate_corrections(words_testing_list, normalized_list_dict_folhaSP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "33.18 + 5.07 39.63\n",
    "68.2% de 217 palavras, desconhecida é 5.07%,  acurácia de erros de grupo 70.51%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
